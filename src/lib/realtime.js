/**
 * OpenAI Realtime API ê´€ë ¨ í•¨ìˆ˜ë“¤
 */
import { get } from 'svelte/store';
import { getPromptForStyle, CONVERSATION_STYLES } from './conversationStyles.js';
import { debugStore } from './stores/debugStore.js';
import { realtimeStore } from './stores/realtimeStore.js';

/**
 * Realtime ì„¸ì…˜ ìƒíƒœ
 */
export function createRealtimeState() {
	return {
		session: null,
		isConnected: false,
		status: 'disconnected', // disconnected, connecting, connected, speaking, listening
		conversationText: '',
		transcriptBuffer: '',
		currentUserInput: '', // í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì¤‘ì¸ í…ìŠ¤íŠ¸
		currentAssistantResponse: '' // í˜„ì¬ AI ì‘ë‹µ ì¤‘ì¸ í…ìŠ¤íŠ¸
	};
}

/**
 * Realtime ì„¸ì…˜ ì—°ê²°
 * @param {object} state - Realtime ìƒíƒœ ê°ì²´
 * @param {function} onError - ì—ëŸ¬ ë°œìƒ ì‹œ ì½œë°±
 * @param {function} onEvent - ì´ë²¤íŠ¸ ë°œìƒ ì‹œ ì½œë°±
 * @param {function} onStatusUpdate - ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°±
 * @param {string|null} selectedStyleId - ì„ íƒëœ ëŒ€í™” ìŠ¤íƒ€ì¼ ID (nullì´ë©´ ê¸°ë³¸)
 */
export async function connectRealtime(state, onError, onEvent, onStatusUpdate, selectedStyleId = null) {
	try {
		state.status = 'connecting';
		debugStore.addLog({
			type: 'info',
			message: 'Realtime ì—°ê²° ì‹œì‘',
			data: { selectedStyleId: selectedStyleId || 'ê¸°ë³¸' }
		});

		// í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
		const instructions = getPromptForStyle(selectedStyleId, true);
		
		// Ephemeral client secret ê°€ì ¸ì˜¤ê¸° (í”„ë¡¬í”„íŠ¸ í¬í•¨)
		const response = await fetch('/api/realtime', {
			method: 'POST',
			headers: {
				'Content-Type': 'application/json'
			},
			body: JSON.stringify({ instructions })
		});

		if (!response.ok) {
			const error = await response.json();
			throw new Error(error.error || 'Failed to get client secret');
		}

		const { clientSecret } = await response.json();
		
		debugStore.addLog({
			type: 'success',
			message: 'Client secret ìƒì„± ì™„ë£Œ',
			data: { 
				styleId: selectedStyleId || 'ê¸°ë³¸',
				promptLength: instructions.length 
			}
		});

		// WebRTC ì—°ê²° ì„¤ì •
		const pc = new RTCPeerConnection({
			iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
		});

		// ë°ì´í„° ì±„ë„ ìƒì„± (ì´ë²¤íŠ¸ ë° ì œì–´ ë©”ì‹œì§€ìš©)
		const dataChannel = pc.createDataChannel('events', {
			ordered: true
		});

		// ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸°
		const micStream = await navigator.mediaDevices.getUserMedia({ 
			audio: {
				channelCount: 1,
				sampleRate: 24000,
				echoCancellation: true,
				noiseSuppression: true
			}
		});

		// ì˜¤ë””ì˜¤ ì¶œë ¥ì„ ìœ„í•œ AudioContext
		const audioCtx = new (window.AudioContext || window.webkitAudioContext)({
			sampleRate: 24000
		});

		// ë§ˆì´í¬ ì…ë ¥ ì¶”ê°€
		micStream.getTracks().forEach(track => {
			pc.addTrack(track, micStream);
		});

		// ì›ê²© ì˜¤ë””ì˜¤ ì²˜ë¦¬
		pc.ontrack = (event) => {
			const [remoteStream] = event.streams;
			const remoteAudioElement = new Audio();
			remoteAudioElement.srcObject = remoteStream;
			remoteAudioElement.autoplay = true;
			remoteAudioElement.play().catch(console.error);
			
			debugStore.addLog({
				type: 'success',
				message: 'WebRTC ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹  ì‹œì‘'
			});
		};

		// ë°ì´í„° ì±„ë„ ì´ë²¤íŠ¸ ì²˜ë¦¬
		dataChannel.onopen = () => {
			console.log('âœ… WebRTC ë°ì´í„° ì±„ë„ ì—°ê²° ì„±ê³µ');
			debugStore.addLog({
				type: 'success',
				message: 'WebRTC ë°ì´í„° ì±„ë„ ì—°ê²° ì„±ê³µ'
			});
			
			// ì„¸ì…˜ ì„¤ì • í™•ì¸ (í”„ë¡¬í”„íŠ¸ê°€ ì´ë¯¸ client_secret ìƒì„± ì‹œ í¬í•¨ë¨)
			console.group('ğŸ¨ ëŒ€í™” ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ì ìš©');
			console.log('ì„ íƒëœ ìŠ¤íƒ€ì¼ ID:', selectedStyleId || '(ê¸°ë³¸ - null)');
			if (selectedStyleId && CONVERSATION_STYLES[selectedStyleId]) {
				console.log('ìŠ¤íƒ€ì¼ ì´ë¦„:', CONVERSATION_STYLES[selectedStyleId].label);
				console.log('ìŠ¤íƒ€ì¼ ì´ëª¨ì§€:', CONVERSATION_STYLES[selectedStyleId].emoji);
			}
			console.log('ì ìš©ëœ í”„ë¡¬í”„íŠ¸ (ì²˜ìŒ 300ì):', instructions.substring(0, 300) + '...');
			console.log('í”„ë¡¬í”„íŠ¸ ì „ì²´ ê¸¸ì´:', instructions.length, 'ì');
			console.groupEnd();
			
			debugStore.addLog({
				type: 'info',
				message: 'í”„ë¡¬í”„íŠ¸ ì ìš© ì™„ë£Œ',
				data: {
					styleId: selectedStyleId || 'ê¸°ë³¸',
					styleName: selectedStyleId && CONVERSATION_STYLES[selectedStyleId] ? CONVERSATION_STYLES[selectedStyleId].label : 'ê¸°ë³¸',
					promptLength: instructions.length
				}
			});
			
			// ì—°ê²° ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
			state.isConnected = true;
			state.status = 'connected';
			if (onStatusUpdate) {
				onStatusUpdate({
					status: 'connected',
					isConnected: true,
					isListening: true,
					isSpeaking: false
				});
			}
		};

		dataChannel.onmessage = (event) => {
			try {
				const data = JSON.parse(event.data);
				
				debugStore.addLog({
					type: 'info',
					message: `WebRTC ë°ì´í„° ì±„ë„ ë©”ì‹œì§€ ìˆ˜ì‹ : ${data.type}`,
					data: data
				});
				
				// ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬
				if (data.type === 'error' || data.type === 'session.error') {
					const errorMessage = data.error?.message || data.message || JSON.stringify(data);
					console.error('âŒ WebRTC ì—ëŸ¬ ë©”ì‹œì§€ ìˆ˜ì‹ :', errorMessage);
					
					debugStore.addLog({
						type: 'error',
						message: `WebRTC ì—ëŸ¬: ${errorMessage}`,
						data: data
					});
					
					state.status = 'error';
					state.isConnected = false;
					
					if (onStatusUpdate) {
						onStatusUpdate({
							status: 'error',
							isConnected: false,
							error: errorMessage
						});
					}
					
					if (onError) {
						onError(errorMessage);
					}
					return;
				}
				
				// ì„¸ì…˜ ê´€ë ¨ ë©”ì‹œì§€ ë¡œê¹…
				if (data.type === 'session.updated' || data.type === 'session.created') {
					console.group('ğŸ“¥ WebRTC ì‘ë‹µ (ì„¸ì…˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ)');
					console.log('ì´ë²¤íŠ¸ íƒ€ì…:', data.type);
					
					if (data.session?.instructions) {
						const receivedInstructions = data.session.instructions;
						console.log('âœ… ì„œë²„ì—ì„œ í™•ì¸ëœ í”„ë¡¬í”„íŠ¸ (ì²˜ìŒ 200ì):', receivedInstructions.substring(0, 200) + '...');
						console.log('âœ… í”„ë¡¬í”„íŠ¸ ê¸¸ì´:', receivedInstructions.length, 'ì');
						
						if (receivedInstructions === instructions) {
							console.log('âœ… í”„ë¡¬í”„íŠ¸ê°€ ì •í™•íˆ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!');
							debugStore.addLog({
								type: 'success',
								message: 'í”„ë¡¬í”„íŠ¸ê°€ ì •í™•íˆ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤!',
								data: {
									promptLength: receivedInstructions.length
								}
							});
						}
					}
					console.groupEnd();
				}
				
				// ë””ë²„ê¹…: ì¤‘ìš”í•œ ì´ë²¤íŠ¸ë§Œ ë¡œê¹… (ë„ˆë¬´ ë§ì€ ë¡œê·¸ ë°©ì§€)
				if (!['response.output_audio.delta'].includes(data.type)) {
					console.log('ğŸ“¥ Realtime ì´ë²¤íŠ¸:', data.type, data);
				}
				
				// ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬
				handleRealtimeEvent(state, data, onStatusUpdate);
				if (onEvent) {
					onEvent(data);
				}
			} catch (error) {
				console.error('âŒ ë°ì´í„° ì±„ë„ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', error);
				console.error('ì›ë³¸ ë©”ì‹œì§€:', event.data);
				debugStore.addLog({
					type: 'error',
					message: 'ë°ì´í„° ì±„ë„ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜',
					data: { error: error.message, rawData: event.data }
				});
			}
		};

		dataChannel.onerror = (error) => {
			console.error('âŒ ë°ì´í„° ì±„ë„ ì˜¤ë¥˜:', error);
			debugStore.addLog({
				type: 'error',
				message: 'ë°ì´í„° ì±„ë„ ì˜¤ë¥˜ ë°œìƒ',
				data: { error: error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜' }
			});
		};

		// SDP offer ìƒì„±
		const offer = await pc.createOffer({
			offerToReceiveAudio: true,
			offerToReceiveVideo: false
		});
		await pc.setLocalDescription(offer);

		debugStore.addLog({
			type: 'info',
			message: 'WebRTC SDP offer ìƒì„± ì™„ë£Œ'
		});

		// OpenAI Realtime APIì— SDP ì „ì†¡
		const sdpResponse = await fetch('https://api.openai.com/v1/realtime/calls', {
			method: 'POST',
			headers: {
				Authorization: `Bearer ${clientSecret}`,
				'Content-Type': 'application/sdp'
			},
			body: offer.sdp
		});

		if (!sdpResponse.ok) {
			const errorText = await sdpResponse.text();
			console.error('WebRTC ì—°ê²° ì‹¤íŒ¨:', errorText);
			debugStore.addLog({
				type: 'error',
				message: 'WebRTC ì—°ê²° ì‹¤íŒ¨',
				data: { error: errorText }
			});
			throw new Error('Failed to establish WebRTC connection');
		}

		const answerSdp = await sdpResponse.text();
		const answer = { type: 'answer', sdp: answerSdp };
		await pc.setRemoteDescription(answer);
		
		debugStore.addLog({
			type: 'success',
			message: 'WebRTC ì—°ê²° ì„±ê³µ'
		});

		// WebRTC ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
		pc.oniceconnectionstatechange = () => {
			console.log('ICE ì—°ê²° ìƒíƒœ:', pc.iceConnectionState);
			debugStore.addLog({
				type: 'info',
				message: `ICE ì—°ê²° ìƒíƒœ: ${pc.iceConnectionState}`
			});
			
			if (pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed') {
				// ì—°ê²° ì™„ë£Œ
			} else if (pc.iceConnectionState === 'failed' || pc.iceConnectionState === 'disconnected') {
				state.status = 'disconnected';
				state.isConnected = false;
				if (onStatusUpdate) {
					onStatusUpdate({
						status: 'disconnected',
						isConnected: false
					});
				}
			}
		};

		pc.onconnectionstatechange = () => {
			console.log('WebRTC ì—°ê²° ìƒíƒœ:', pc.connectionState);
			debugStore.addLog({
				type: 'info',
				message: `WebRTC ì—°ê²° ìƒíƒœ: ${pc.connectionState}`
			});
		};

		state.session = { pc, dataChannel, micStream, audioCtx };
		
		// ì„¸ì…˜ì„ ìŠ¤í† ì–´ì— ì €ì¥ (ì—°ê²° ì™„ë£Œ í›„)
		realtimeStore.setSession(state.session);
	} catch (error) {
		console.error('Realtime ì—°ê²° ì‹¤íŒ¨:', error);
		const message = error.message || 'Realtime ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.';
		debugStore.addLog({
			type: 'error',
			message: 'Realtime ì—°ê²° ì‹¤íŒ¨',
			data: { error: message, stack: error.stack }
		});
		state.status = 'disconnected';
		if (onError) {
			onError(message);
		}
	}
}

/**
 * Realtime ì´ë²¤íŠ¸ ì²˜ë¦¬
 * @param {object} state - Realtime ìƒíƒœ ê°ì²´
 * @param {object} event - ì´ë²¤íŠ¸ ë°ì´í„°
 * @param {function} onStatusUpdate - ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°±
 */
function handleRealtimeEvent(state, event, onStatusUpdate) {
	let updates = {};

	switch (event.type) {
		case 'response.output_text.delta':
			console.log('ğŸ“ AI í…ìŠ¤íŠ¸ ì‘ë‹µ ë¸íƒ€:', event.delta);
			state.transcriptBuffer += event.delta;
			state.conversationText += event.delta;
			state.currentAssistantResponse += event.delta;
			// ì‹¤ì‹œê°„ìœ¼ë¡œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸
			realtimeStore.updateStatus({
				currentAssistantResponse: state.currentAssistantResponse
			});
			// ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
			const currentMessages = get(realtimeStore).messages || [];
			if (currentMessages.length > 0 && currentMessages[currentMessages.length - 1].role === 'assistant') {
				realtimeStore.updateLastMessage(state.currentAssistantResponse);
			} else {
				console.log('âœ… ìƒˆ AI ë©”ì‹œì§€ ì¶”ê°€:', state.currentAssistantResponse);
				realtimeStore.addMessage({
					id: `msg-${Date.now()}-${Math.random()}`,
					role: 'assistant',
					content: state.currentAssistantResponse,
					timestamp: new Date().toISOString()
				});
			}
			updates = {
				conversationText: state.conversationText,
				status: state.status
			};
			break;

		case 'response.output_text.done':
			state.conversationText += '\n';
			state.transcriptBuffer = '';
			// AI ì‘ë‹µ ì™„ë£Œ - ë©”ì‹œì§€ ìµœì¢… ì €ì¥
			if (state.currentAssistantResponse.trim()) {
				const currentMessages = get(realtimeStore).messages || [];
				if (currentMessages.length > 0 && currentMessages[currentMessages.length - 1].role === 'assistant') {
					realtimeStore.updateLastMessage(state.currentAssistantResponse.trim());
				}
				state.currentAssistantResponse = '';
				realtimeStore.updateStatus({ currentAssistantResponse: '' });
			}
			updates = {
				conversationText: state.conversationText,
				status: state.status
			};
			break;

		case 'response.output_audio.delta':
			// ì˜¤ë””ì˜¤ ë¸íƒ€ëŠ” WebRTCë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨
			break;

		case 'response.output_audio.done':
			state.status = 'listening';
			updates = { 
				status: 'listening',
				isListening: true,
				isSpeaking: false
			};
			break;

		case 'conversation.item.input_audio_transcription.completed':
			state.status = 'speaking';
			// ì‚¬ìš©ì ìŒì„± ì…ë ¥ ì™„ë£Œ - ë©”ì‹œì§€ ì¶”ê°€
			// OpenAI Realtime APIì—ì„œ transcriptëŠ” event.item.input_audio_transcription.transcriptì— ìˆìŒ
			console.log('ğŸ¤ ìŒì„± ì…ë ¥ ì™„ë£Œ ì´ë²¤íŠ¸:', event);
			const userText = event.item?.input_audio_transcription?.transcript || 
			                  event.transcript || 
			                  event.item?.transcript || 
			                  '';
			console.log('ğŸ“ ì¶”ì¶œëœ ì‚¬ìš©ì í…ìŠ¤íŠ¸:', userText);
			if (userText.trim()) {
				state.currentUserInput = userText.trim();
				realtimeStore.addMessage({
					id: `msg-${Date.now()}-${Math.random()}`,
					role: 'user',
					content: userText.trim(),
					timestamp: new Date().toISOString()
				});
				console.log('âœ… ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ë¨:', userText.trim());
				state.currentUserInput = '';
			} else {
				console.warn('âš ï¸ ì‚¬ìš©ì í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.');
			}
			updates = { 
				status: 'speaking',
				isListening: false,
				isSpeaking: true
			};
			break;

		case 'conversation.item.input_text.done':
			// í…ìŠ¤íŠ¸ ì…ë ¥ ì™„ë£Œ - ì´ë¯¸ UIì— í‘œì‹œë˜ì—ˆìœ¼ë¯€ë¡œ ìƒíƒœë§Œ ì—…ë°ì´íŠ¸
			console.log('âœ… í…ìŠ¤íŠ¸ ì…ë ¥ ì™„ë£Œ ì´ë²¤íŠ¸:', event);
			state.status = 'speaking';
			updates = { 
				status: 'speaking',
				isListening: false,
				isSpeaking: true
			};
			break;
		
		case 'conversation.item.added':
			// ëŒ€í™” ì•„ì´í…œ ì¶”ê°€ë¨
			console.log('âœ… ëŒ€í™” ì•„ì´í…œ ì¶”ê°€ë¨:', event);
			// í…ìŠ¤íŠ¸ ì…ë ¥ì¸ ê²½ìš° ë©”ì‹œì§€ê°€ ì´ë¯¸ UIì— ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
			break;
		
		case 'conversation.item.done':
			// ëŒ€í™” ì•„ì´í…œ ì™„ë£Œ
			console.log('âœ… ëŒ€í™” ì•„ì´í…œ ì™„ë£Œ:', event);
			// ì‘ë‹µ ìƒì„± ëŒ€ê¸° ìƒíƒœë¡œ ë³€ê²½
			state.status = 'speaking';
			updates = { 
				status: 'speaking',
				isListening: false,
				isSpeaking: true
			};
			break;
		
		case 'response.created':
			// ì‘ë‹µ ìƒì„± ì‹œì‘
			console.log('âœ… ì‘ë‹µ ìƒì„± ì‹œì‘:', event);
			break;
		
		case 'response.output_item.added':
			// ì‘ë‹µ ì•„ì´í…œ ì¶”ê°€ë¨
			console.log('âœ… ì‘ë‹µ ì•„ì´í…œ ì¶”ê°€ë¨:', event);
			break;

		case 'session.created':
		case 'session.updated':
			state.status = 'connected';
			state.isConnected = true;
			console.log('âœ… ì„¸ì…˜ ì—…ë°ì´íŠ¸ë¨:', event.session?.output_modalities);
			updates = { 
				status: 'connected', 
				isConnected: true,
				isListening: true,
				isSpeaking: false
			};
			break;

		case 'session.error':
			state.status = 'error';
			updates = {
				status: 'error',
				isConnected: false,
				error: event.error || 'ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'
			};
			break;

		case 'session.closed':
			state.status = 'disconnected';
			updates = {
				status: 'disconnected',
				isConnected: false,
				isListening: false,
				isSpeaking: false
			};
			break;
	}

	// ìƒíƒœ ì—…ë°ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì½œë°± í˜¸ì¶œ
	if (Object.keys(updates).length > 0 && onStatusUpdate) {
		onStatusUpdate(updates);
	}
}

/**
 * í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
 * @param {object} session - Realtime ì„¸ì…˜ ê°ì²´
 * @param {string} text - ì „ì†¡í•  í…ìŠ¤íŠ¸
 */
export async function sendTextMessage(session, text) {
	if (!session || !session.dataChannel || session.dataChannel.readyState !== 'open') {
		throw new Error('ë°ì´í„° ì±„ë„ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
	}

	const message = {
		type: 'conversation.item.create',
		item: {
			type: 'message',
			role: 'user',
			content: [
				{
					type: 'input_text',
					text: text
				}
			]
		}
	};

	console.log('ğŸ“¤ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡:', message);
	session.dataChannel.send(JSON.stringify(message));
	
	// í…ìŠ¤íŠ¸ ì…ë ¥ í›„ ì‘ë‹µ ìƒì„± ìš”ì²­ (ì•½ê°„ì˜ ì§€ì—° í›„)
	// í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œì—ëŠ” í…ìŠ¤íŠ¸ ì‘ë‹µë„ ë°›ê¸° ìœ„í•´ ë³„ë„ ì„¸ì…˜ ì—…ë°ì´íŠ¸ í•„ìš”
	// í•˜ì§€ë§Œ ì„¸ì…˜ ë ˆë²¨ì—ì„œëŠ” ['text'] ë˜ëŠ” ['audio']ë§Œ ì§€ì›ë˜ë¯€ë¡œ,
	// response.createì—ì„œ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­
	setTimeout(() => {
		// ë¨¼ì € ì„¸ì…˜ì„ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì—…ë°ì´íŠ¸ ì‹œë„
		const sessionUpdate = {
			type: 'session.update',
			session: {
				output_modalities: ['text', 'audio']
			}
		};
		console.log('ğŸ“¤ ì„¸ì…˜ ì—…ë°ì´íŠ¸ (í…ìŠ¤íŠ¸+ì˜¤ë””ì˜¤):', sessionUpdate);
		
		// ì„¸ì…˜ ì—…ë°ì´íŠ¸ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, response.createë„ í•¨ê»˜ ì‹œë„
		const responseRequest = {
			type: 'response.create'
		};
		
		try {
			// ì„¸ì…˜ ì—…ë°ì´íŠ¸ ì‹œë„ (ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ)
			session.dataChannel.send(JSON.stringify(sessionUpdate));
		} catch (error) {
			console.warn('ì„¸ì…˜ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥):', error);
		}
		
		// ì‘ë‹µ ìƒì„± ìš”ì²­
		setTimeout(() => {
			console.log('ğŸ“¤ ì‘ë‹µ ìƒì„± ìš”ì²­:', responseRequest);
			session.dataChannel.send(JSON.stringify(responseRequest));
		}, 100);
	}, 200);
	
	debugStore.addLog({
		type: 'info',
		message: 'í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡',
		data: { text: text.substring(0, 50) + (text.length > 50 ? '...' : '') }
	});
}

/**
 * Realtime ì„¸ì…˜ ì¢…ë£Œ
 * @param {object} state - Realtime ìƒíƒœ ê°ì²´
 */
export async function disconnectRealtime(state, onStatusUpdate = null) {
	if (!state.session) return;
	
	const { dataChannel, pc, micStream, audioCtx } = state.session;
	
	// ë°ì´í„° ì±„ë„ ì¢…ë£Œ
	if (dataChannel) {
		dataChannel.close();
	}

	// WebRTC ì—°ê²° ì¢…ë£Œ
	if (pc) {
		pc.close();
	}

	// ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
	if (micStream) {
		micStream.getTracks().forEach(track => track.stop());
	}

	// ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ
	if (audioCtx) {
		await audioCtx.close();
	}
	
	debugStore.addLog({
		type: 'info',
		message: 'WebRTC ì—°ê²° ì¢…ë£Œ'
	});
	
		// ìƒíƒœ ì´ˆê¸°í™”
		state.session = null;
		state.isConnected = false;
		state.status = 'disconnected';
		state.transcriptBuffer = '';
		state.currentUserInput = '';
		state.currentAssistantResponse = '';
	
	// ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± í˜¸ì¶œ
	if (onStatusUpdate) {
		onStatusUpdate({
			status: 'disconnected',
			isConnected: false,
			isListening: false,
			isSpeaking: false
		});
	}
}

